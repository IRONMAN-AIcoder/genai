{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrfiEVbAyMZDoqn1F1OaZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IRONMAN-AIcoder/genai/blob/main/Gen5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J2M1ktp32UH",
        "outputId": "b18b61cd-81a7-4733-d8ee-ff2698d8f37d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.13.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=ca10d9485c21d5308ba4e8275d3f190677ef20fd4f4e7d7cd29a0ced135fd503\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pFNme2T4ATd",
        "outputId": "da3cd3fd-9632-4290-a143-53b2f2bea2d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qupt_FvZ5GAT",
        "outputId": "65f24f6e-3a2f-4877-e45f-6ec78818c66e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.49)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.19)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.11.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-cpp-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cQ31_K65QPr",
        "outputId": "0489e0fc-0b5b-4a01-bb43-7a208da407e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp311-cp311-linux_x86_64.whl size=5959590 sha256=5ca31e9da076788ebfc7457dd164ec5e6ad9e30993573b76a1092488dc2449c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/03/66/eb3810eafd55d921b2be32896d1f44313996982360663aa80b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sffYb1g7otA",
        "outputId": "44ac8f0e-d053-44bc-88a8-da0505ee78dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import WikipediaLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI  # Using OpenRouter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Set OpenRouter API Key from an environment variable\n",
        "OPENROUTER_API_KEY = \"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\"  # Ensure you set this in your environment\n",
        "\n",
        "# Initialize Wikipedia Loader\n",
        "def load_wikipedia_data(query):\n",
        "    loader = WikipediaLoader(query=query, lang='en')\n",
        "    return loader.load()\n",
        "\n",
        "# Initialize embeddings model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Load Wikipedia data and create FAISS index\n",
        "def build_faiss_index(topic):\n",
        "    documents = load_wikipedia_data(topic)\n",
        "    vector_db = FAISS.from_documents(documents, embedding_model)\n",
        "    return vector_db\n",
        "\n",
        "# Load OpenRouter GPT model\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"openai/gpt-3.5-turbo\",\n",
        "    openai_api_key=OPENROUTER_API_KEY,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# Create Retrieval QA Chain\n",
        "def create_rag_chain(vector_db):\n",
        "    retriever = vector_db.as_retriever()\n",
        "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    topic = input(\"Enter a topic to fetch Wikipedia data: \")\n",
        "    vector_db = build_faiss_index(topic)\n",
        "    qa_chain = create_rag_chain(vector_db)\n",
        "\n",
        "    while True:\n",
        "        user_query = input(f\"Ask a question about {topic} (or type 'exit' to quit): \")\n",
        "        if user_query.lower() == 'exit':\n",
        "            break\n",
        "        response = qa_chain.run(user_query)\n",
        "        print(\"Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w724_WntAuUu",
        "outputId": "4dc493f0-bc22-4b7f-bc33-98037401b48d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a topic to fetch Wikipedia data: india\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question about india (or type 'exit' to quit): what is a good place to visit in india\n",
            "Response: India is a country with a rich cultural heritage and diverse landscapes, offering a wide range of attractions for visitors. Some popular places to visit in India include:\n",
            "\n",
            "1. **Taj Mahal**: Located in Agra, the Taj Mahal is a UNESCO World Heritage Site and one of the most iconic landmarks in India.\n",
            "\n",
            "2. **Jaipur**: Known as the Pink City, Jaipur is famous for its historic palaces, forts, and vibrant culture.\n",
            "\n",
            "3. **Goa**: A coastal state known for its beautiful beaches, vibrant nightlife, and Portuguese-influenced architecture.\n",
            "\n",
            "4. **Kerala**: Known as \"God's Own Country,\" Kerala offers scenic backwaters, lush greenery, and Ayurvedic treatments.\n",
            "\n",
            "5. **Varanasi**: One of the oldest cities in the world, Varanasi is a spiritual hub on the banks of the Ganges River, known for its ghats and temples.\n",
            "\n",
            "6. **Ranthambore National Park**: A popular destination for wildlife enthusiasts, offering a chance to spot tigers in their natural habitat.\n",
            "\n",
            "7. **Darjeeling**: Famous for its tea plantations, Darjeeling offers stunning views of the Himalayas and is known for its toy train.\n",
            "\n",
            "8. **Mysore**: Known for its royal heritage, Mysore is home to the grand Mysore Palace and vibrant Dasara festival.\n",
            "\n",
            "These are just a few of the many amazing places to visit in India. Each region of the country has its own unique attractions, so you can choose based on your interests and preferences.\n",
            "Ask a question about india (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fitz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "dfbkSEPDEDAx",
        "outputId": "d9507bad-4dff-4afb-9bbd-2776afa0b4e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fitz\n",
            "  Using cached fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.11/dist-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.11/dist-packages (from fitz) (7.2.0)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.11/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from fitz) (5.3.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.11/dist-packages (from fitz) (1.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fitz) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fitz) (2.2.2)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.11/dist-packages (from fitz) (1.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fitz) (1.14.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2->fitz) (3.2.3)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (4.13.0)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (8.1.8)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.4.2)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.0.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.20.1)\n",
            "Requirement already satisfied: traits>=6.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (7.0.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.18.0)\n",
            "Requirement already satisfied: acres in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: etelemetry>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (1.28)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (5.3.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (2.32.3)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.11/dist-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (2025.1.31)\n",
            "Using cached fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: fitz\n",
            "Successfully installed fitz-0.0.1.dev2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fitz"
                ]
              },
              "id": "ac6627d66a7940c7a1106dde0c69c848"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall fitz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZcuwS0JEISw",
        "outputId": "823bb1da-2962-4a39-bbd3-1e61412267b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: fitz 0.0.1.dev2\n",
            "Uninstalling fitz-0.0.1.dev2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/fitz\n",
            "    /usr/local/bin/log2design.py\n",
            "    /usr/local/lib/python3.11/dist-packages/.DS_Store\n",
            "    /usr/local/lib/python3.11/dist-packages/fitz-0.0.1.dev2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/fitz/*\n",
            "    /usr/local/lib/python3.11/dist-packages/scripts/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.11/dist-packages/scripts/readme-gen/readme_gen.py\n",
            "Proceed (Y/n)? Y\n",
            "\n",
            "  Successfully uninstalled fitz-0.0.1.dev2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4LXOdaVEbJI",
        "outputId": "98e5fd61-77c2-461a-da41-e7cedcc0f793"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF for PDF processing\n",
        "import os\n",
        "from google.colab import files  # For file upload in Colab\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Function to upload PDF in Colab\n",
        "def upload_pdf():\n",
        "    print(\"Please upload your PDF file...\")\n",
        "    uploaded = files.upload()\n",
        "    pdf_path = list(uploaded.keys())[0]  # Get the filename of the uploaded PDF\n",
        "    return pdf_path\n",
        "\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Process the PDF and build FAISS index\n",
        "def build_faiss_index(pdf_path, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    if not text:\n",
        "        print(\"No text found in PDF. Please try a different file.\")\n",
        "        return None\n",
        "\n",
        "    print(\"Splitting text into chunks...\")\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    text_chunks = text_splitter.split_text(text)\n",
        "\n",
        "    documents = [Document(page_content=chunk) for chunk in text_chunks]\n",
        "\n",
        "    print(\"Generating embeddings...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
        "    vector_db = FAISS.from_documents(documents, embedding_model)\n",
        "\n",
        "    print(\"FAISS index created successfully!\")\n",
        "    return vector_db\n",
        "\n",
        "# Load OpenRouter GPT model (Replace with your API key)\n",
        "OPENROUTER_API_KEY = \"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\"  # Replace with your OpenRouter API key\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"openai/gpt-3.5-turbo\",  # Change model if needed\n",
        "    openai_api_key=OPENROUTER_API_KEY,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# Create Retrieval QA Chain\n",
        "def create_rag_chain(vector_db):\n",
        "    retriever = vector_db.as_retriever()\n",
        "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "# Main function\n",
        "if __name__ == '__main__':\n",
        "    pdf_path = upload_pdf()  # Upload PDF in Colab\n",
        "    vector_db = build_faiss_index(pdf_path)\n",
        "\n",
        "    if vector_db is None:\n",
        "        print(\"Failed to process PDF. Exiting.\")\n",
        "    else:\n",
        "        qa_chain = create_rag_chain(vector_db)\n",
        "        print(\"\\n‚úÖ PDF processing complete. You can now ask questions!\")\n",
        "\n",
        "        while True:\n",
        "            user_query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
        "            if user_query.lower() == 'exit':\n",
        "                print(\"Goodbye! üëã\")\n",
        "                break\n",
        "            response = qa_chain.run(user_query)\n",
        "            print(\"\\nResponse:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "X3Sidng9HN5_",
        "outputId": "7bebbda0-ff29-427c-dc73-9c8c4bf6a693"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d82171b-ec49-48f0-b762-9dac7aaa814a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d82171b-ec49-48f0-b762-9dac7aaa814a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2821, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2417, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1781, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2857, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3339, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ask.pdf to ask (1).pdf\n",
            "Extracting text from PDF...\n",
            "Splitting text into chunks...\n",
            "Generating embeddings...\n",
            "FAISS index created successfully!\n",
            "\n",
            "‚úÖ PDF processing complete. You can now ask questions!\n",
            "\n",
            "Ask a question (or type 'exit' to quit): how many international students are there\n",
            "\n",
            "Response: The essay mentions that the world's first university established in Takshila, India, in 700 BCE hosted over 10,500 international students studying an array of over 60 subjects. Additionally, Nalanda University in the 4th century BCE was another significant educational institution in India. The specific number of international students at Nalanda University is not mentioned in the provided context.\n",
            "\n",
            "Ask a question (or type 'exit' to quit): exit\n",
            "Goodbye! üëã\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "pdf_path = r\"C:\\Users\\student\\Downloads\\ask.pdf\"\n",
        "if os.path.exists(pdf_path):\n",
        "    print(\"Success! The file was found.\")\n",
        "else:\n",
        "    print(\"Error: File not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI3SH_RoEnIQ",
        "outputId": "94ed6b29-1c22-466b-ce3e-a0983d102efe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_vG_d8URqAJ",
        "outputId": "9069e86e-edf4-4ed2-b4d3-ba0c402336b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import fitz  # PyMuPDF for PDF handling (if needed)\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI  # LLaMA/Mistral via OpenRouter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "\n",
        "# PubMed API Constants\n",
        "PUBMED_API_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "PUBMED_FETCH_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "\n",
        "# Initialize embeddings model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# OpenRouter API Key for LLaMA/Mistral\n",
        "OPENROUTER_API_KEY = \"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\"\n",
        "\n",
        "# Initialize LLM (LLaMA/Mistral)\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"mistralai/mistral-7b-instruct\",  # You can change to \"meta-llama/llama-2-7b-chat\"\n",
        "    openai_api_key=OPENROUTER_API_KEY,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "def fetch_pubmed_articles(query, max_results=5):\n",
        "    \"\"\" Fetch PubMed article abstracts based on query. \"\"\"\n",
        "    params = {\n",
        "        \"db\": \"pubmed\",\n",
        "        \"term\": query,\n",
        "        \"retmode\": \"json\",\n",
        "        \"retmax\": max_results\n",
        "    }\n",
        "    response = requests.get(PUBMED_API_URL, params=params)\n",
        "    article_ids = response.json().get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "\n",
        "    if not article_ids:\n",
        "        return []\n",
        "\n",
        "    # Fetch article details\n",
        "    fetch_params = {\n",
        "        \"db\": \"pubmed\",\n",
        "        \"id\": \",\".join(article_ids),\n",
        "        \"retmode\": \"text\",\n",
        "        \"rettype\": \"abstract\"\n",
        "    }\n",
        "    response = requests.get(PUBMED_FETCH_URL, params=fetch_params)\n",
        "    return response.text.split(\"\\n\\n\")  # Split articles\n",
        "\n",
        "def build_faiss_index(articles):\n",
        "    \"\"\" Process articles into FAISS vector store. \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    text_chunks = [chunk for article in articles for chunk in text_splitter.split_text(article)]\n",
        "\n",
        "    documents = [Document(page_content=chunk) for chunk in text_chunks]\n",
        "    vector_db = FAISS.from_documents(documents, embedding_model)\n",
        "    return vector_db\n",
        "\n",
        "def create_rag_chain(vector_db):\n",
        "    \"\"\" Create Retrieval-Augmented Generation (RAG) Chain. \"\"\"\n",
        "    retriever = vector_db.as_retriever()\n",
        "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    user_query = input(\"Enter a medical topic (e.g., 'Diabetes treatment', 'COVID-19 vaccines'): \")\n",
        "    print(f\"Fetching articles related to: {user_query}\")\n",
        "\n",
        "    articles = fetch_pubmed_articles(user_query)\n",
        "\n",
        "    if not articles:\n",
        "        print(\"No relevant articles found on PubMed.\")\n",
        "    else:\n",
        "        print(\"Building vector database...\")\n",
        "        vector_db = build_faiss_index(articles)\n",
        "        qa_chain = create_rag_chain(vector_db)\n",
        "\n",
        "        print(\"System ready! Ask health-related questions.\")\n",
        "        while True:\n",
        "            question = input(\"Ask a health question (or type 'exit' to quit): \")\n",
        "            if question.lower() == 'exit':\n",
        "                break\n",
        "            response = qa_chain.run(question)\n",
        "            print(\"Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7YA1V_nU-S_",
        "outputId": "aa6be7de-0cd1-4ff8-f159-143346bcfeea"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a medical topic (e.g., 'Diabetes treatment', 'COVID-19 vaccines'): covid 19\n",
            "Fetching articles related to: covid 19\n",
            "Building vector database...\n",
            "System ready! Ask health-related questions.\n",
            "Ask a health question (or type 'exit' to quit): how it is caused\n",
            "Response:  The information provided does not explicitly explain the cause of any condition or disease. These are DOIs (Digital Object Identifiers) and PMIDs (PubMed Identifier), which are used to identify and cite research articles. To find the cause of a condition or disease, you would need to access the full text of the research article associated with these identifiers.\n",
            "Ask a health question (or type 'exit' to quit): how covid 19 spreads\n",
            "Response:  The text does not provide specific information on how COVID-19 spreads. However, it does mention that lower respiratory infections (LRIs) caused by Streptococcus pneumoniae remained a leading cause from 1990 to 2021. This suggests that LRIs, such as COVID-19, can spread through respiratory droplets when an infected person coughs, sneezes, or talks. Please consult the CDC or WHO for more detailed information on how COVID-19 spreads.\n",
            "Ask a health question (or type 'exit' to quit): how is it diagonised\n",
            "Response:  The provided context does not contain information about the diagnosis of any specific condition. These are citations for two separate research articles, and they list authors and their affiliations, but do not provide details about the diagnosis methods or conditions being studied. For information about the diagnosis of a specific condition, you should refer to the full text of the articles or consult a healthcare professional.\n",
            "Ask a health question (or type 'exit' to quit): how covid  19 is diagonised\n",
            "Response:  COVID-19 is primarily diagnosed through a combination of methods, including:\n",
            "\n",
            "1. Real-time Reverse Transcription Polymerase Chain Reaction (RT-PCR) testing: This is the most common method used to diagnose COVID-19. It detects the genetic material (RNA) of the SARS-CoV-2 virus in samples collected from the nose or throat.\n",
            "\n",
            "2. Antigen tests: These tests can provide results more quickly than RT-PCR tests, but they may be less accurate, particularly during the early stages of infection.\n",
            "\n",
            "3. Chest X-ray or CT scan: These imaging tests may be used to help diagnose COVID-19 when other methods are inconclusive, especially in severe cases or when the patient is experiencing respiratory symptoms.\n",
            "\n",
            "4. Serology tests: These tests look for antibodies in the blood that the immune system produces in response to the SARS-CoV-2 virus. They can help confirm a past infection, but they are not typically used for diagnosing active infections because they may take several days to a week to become positive after infection.\n",
            "Ask a health question (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import fitz  # PyMuPDF (for PDF handling)\n",
        "import whisper  # OpenAI Whisper (for speech recognition)\n",
        "import faiss  # Facebook AI Similarity Search\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files  # For file uploads in Colab\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Set OpenRouter API Key (Replace with your actual key)\n",
        "OPENROUTER_API_KEY =\"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\"\n",
        "# Load LLM (Mistral or LLaMA via OpenRouter)\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"mistralai/mistral-7b-instruct\",\n",
        "    temperature=0.7,\n",
        "    openai_api_key=OPENROUTER_API_KEY,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# Load Embedding Model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Load CLIP Model for Image Processing\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Load Whisper Model for Audio Processing\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# === FILE UPLOAD FUNCTIONS ===\n",
        "def upload_file(file_type):\n",
        "    \"\"\"Upload a file of a specific type (PDF, image, or audio).\"\"\"\n",
        "    print(f\"Please upload your {file_type} file (or skip if not required)...\")\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())[0] if uploaded else None  # Return filename if uploaded, else None\n",
        "\n",
        "# === TEXT PROCESSING ===\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file.\"\"\"\n",
        "    if not pdf_path:\n",
        "        return None\n",
        "    doc = fitz.open(pdf_path)\n",
        "    return \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
        "\n",
        "def build_text_faiss(text_data):\n",
        "    \"\"\"Create a FAISS index for text-based retrieval.\"\"\"\n",
        "    if not text_data:\n",
        "        return None\n",
        "    text_splitter = text_data.split(\"\\n\")  # Split text into sentences\n",
        "    text_docs = [Document(page_content=chunk) for chunk in text_splitter if chunk.strip()]\n",
        "    vector_db = FAISS.from_documents(text_docs, embedding_model)\n",
        "    return vector_db\n",
        "\n",
        "# === IMAGE PROCESSING ===\n",
        "def encode_image(image_path):\n",
        "    \"\"\"Encode an image using CLIP.\"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        image_features = clip_model.get_image_features(**inputs)\n",
        "    return image_features.cpu().numpy()\n",
        "\n",
        "def build_image_faiss(image_paths):\n",
        "    \"\"\"Create a FAISS index for image-based retrieval.\"\"\"\n",
        "    if not image_paths:\n",
        "        return None, {}\n",
        "\n",
        "    d = 512  # CLIP feature dimension\n",
        "    index = faiss.IndexFlatL2(d)\n",
        "    image_store = {}\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img_vector = encode_image(img_path)\n",
        "        index.add(img_vector)\n",
        "        image_store[len(image_store)] = img_path  # Store mapping\n",
        "\n",
        "    return index, image_store\n",
        "\n",
        "# === AUDIO PROCESSING ===\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribe audio to text using Whisper.\"\"\"\n",
        "    if not audio_path:\n",
        "        return None\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def build_audio_faiss(audio_texts):\n",
        "    \"\"\"Create FAISS index for transcribed audio data.\"\"\"\n",
        "    if not audio_texts:\n",
        "        return None\n",
        "    audio_docs = [Document(page_content=txt) for txt in audio_texts]\n",
        "    vector_db = FAISS.from_documents(audio_docs, embedding_model)\n",
        "    return vector_db\n",
        "\n",
        "# === MULTIMODAL QUERY HANDLING ===\n",
        "def multimodal_query(query, text_db, image_index, image_store, audio_db):\n",
        "    \"\"\"Retrieve relevant results from text, image, and audio sources.\"\"\"\n",
        "\n",
        "    # Text-based retrieval\n",
        "    text_result = text_db.similarity_search(query, k=1) if text_db else None\n",
        "\n",
        "    # Image-based retrieval\n",
        "    image_result = None\n",
        "    if image_index is not None and os.path.exists(query):  # If query is an image file\n",
        "        query_embedding = encode_image(query)\n",
        "        distances, indices = image_index.search(query_embedding, k=1)\n",
        "        image_result = image_store.get(indices[0][0], None)\n",
        "\n",
        "    # Audio-based retrieval\n",
        "    audio_result = audio_db.similarity_search(query, k=1) if audio_db else None\n",
        "\n",
        "    return {\n",
        "        \"text\": text_result[0].page_content if text_result else \"No relevant text found.\",\n",
        "        \"image\": image_result if image_result else \"No matching image found.\",\n",
        "        \"audio\": audio_result[0].page_content if audio_result else \"No relevant audio found.\"\n",
        "    }\n",
        "\n",
        "# === MAIN EXECUTION ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Upload files via Colab (optional uploads)\n",
        "    pdf_path = upload_file(\"PDF\")\n",
        "    image_paths = [upload_file(\"image\")] if input(\"Upload an image? (y/n): \").lower() == \"y\" else None\n",
        "    audio_path = upload_file(\"audio\") if input(\"Upload an audio file? (y/n): \").lower() == \"y\" else None\n",
        "\n",
        "    print(\"\\nüîÑ Processing PDF...\")\n",
        "    text_faiss_db = build_text_faiss(extract_text_from_pdf(pdf_path)) if pdf_path else None\n",
        "\n",
        "    print(\"üîÑ Processing Images...\")\n",
        "    image_faiss_index, image_store = build_image_faiss(image_paths) if image_paths else (None, {})\n",
        "\n",
        "    print(\"üîÑ Processing Audio...\")\n",
        "    transcribed_text = transcribe_audio(audio_path) if audio_path else None\n",
        "    audio_faiss_db = build_audio_faiss([transcribed_text]) if transcribed_text else None\n",
        "\n",
        "    print(\"\\n‚úÖ System Ready! Ask multimodal queries...\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nEnter a text query (or provide an image/audio file path, type 'exit' to quit): \")\n",
        "        if user_query.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        results = multimodal_query(user_query, text_faiss_db, image_faiss_index, image_store, audio_faiss_db)\n",
        "\n",
        "        print(\"\\nüîπ **Results:**\")\n",
        "        print(f\"üìñ **Text Answer:** {results['text']}\")\n",
        "        print(f\"üñºÔ∏è **Image Match:** {results['image']}\")\n",
        "        print(f\"üîä **Audio Answer:** {results['audio']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "unDmh-eNTk7x",
        "outputId": "a1d5a195-0563-4cab-fb8b-d98ba98d3f87"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF file (or skip if not required)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b9049d4a-da8c-45b0-97bf-a03b6f93e00e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b9049d4a-da8c-45b0-97bf-a03b6f93e00e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving ask.pdf to ask (5).pdf\n",
            "Upload an image? (y/n): n\n",
            "Upload an audio file? (y/n): n\n",
            "\n",
            "üîÑ Processing PDF...\n",
            "üîÑ Processing Images...\n",
            "üîÑ Processing Audio...\n",
            "\n",
            "‚úÖ System Ready! Ask multimodal queries...\n",
            "\n",
            "Enter a text query (or provide an image/audio file path, type 'exit' to quit): what is modern physics\n",
            "\n",
            "üîπ **Results:**\n",
            "üìñ **Text Answer:** modern physics. The research draws from ancient \n",
            "üñºÔ∏è **Image Match:** No matching image found.\n",
            "üîä **Audio Answer:** No relevant audio found.\n",
            "\n",
            "Enter a text query (or provide an image/audio file path, type 'exit' to quit): how many students are there\n",
            "\n",
            "üîπ **Results:**\n",
            "üìñ **Text Answer:** India, in 700 BCE, hosting over 10,500 international students studying an array of over 60 \n",
            "üñºÔ∏è **Image Match:** No matching image found.\n",
            "üîä **Audio Answer:** No relevant audio found.\n",
            "\n",
            "Enter a text query (or provide an image/audio file path, type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skF5SgirWVhT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}